{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-19T08:33:31.359415Z",
     "start_time": "2024-01-19T08:33:30.357062500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# with open('pos.txt','r',encoding='utf-8') as reader_pos:\n",
    "#     with open('neg.txt','r',encoding='utf-8') as reader_neg:\n",
    "#         with open('bert_posneg.txt','w',encoding='utf-8') as bert_write:\n",
    "#             for pos in reader_pos:\n",
    "#                 bert_write.write(pos.strip()+'\\t'+'1')\n",
    "#                 bert_write.write('\\n')\n",
    "#             for neg in reader_neg:\n",
    "#                 bert_write.write(neg.strip()+'\\t'+'0')\n",
    "#                 bert_write.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese', do_lower_case=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T08:35:31.573007900Z",
     "start_time": "2024-01-19T08:35:31.014495200Z"
    }
   },
   "id": "fe3d00372e924fb0"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "max_length = 110\n",
    "batch_size = 6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T08:54:34.070824400Z",
     "start_time": "2024-01-19T08:54:34.057860200Z"
    }
   },
   "id": "d1041e224a12a3cb"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def convert_example_to_feature(review):\n",
    "    return tokenizer.encode_plus(review,\n",
    "                                 add_special_tokens=True,  # add [CLS], [SEP]\n",
    "                                 max_length=max_length,  # max length of the text that can go to BERT\n",
    "                                 pad_to_max_length=True,  # add [PAD] tokens\n",
    "                                 return_attention_mask=True,  # add attention mask to not focus on pad tokens\n",
    "                                 )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T08:54:34.781024600Z",
     "start_time": "2024-01-19T08:54:34.757086900Z"
    }
   },
   "id": "8086e90e69e9a38e"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"token_type_ids\": token_type_ids,\n",
    "        \"attention_mask\": attention_masks,\n",
    "    }, label\n",
    "\n",
    "\n",
    "def encode_examples(ds, limit=-1):\n",
    "    # prepare list, so that we can build up final TensorFlow dataset from slices.\n",
    "    input_ids_list = []\n",
    "    token_type_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    label_list = []\n",
    "    if (limit > 0):\n",
    "        ds = ds.take(limit)\n",
    "    for row in ds:\n",
    "        review, label = row.split('\\t')\n",
    "        bert_input = convert_example_to_feature(review)\n",
    "        input_ids_list.append(bert_input['input_ids'])\n",
    "        token_type_ids_list.append(bert_input['token_type_ids'])\n",
    "        attention_mask_list.append(bert_input['attention_mask'])\n",
    "        label_list.append([int(label)])\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T09:27:31.813935600Z",
     "start_time": "2024-01-19T09:27:31.800946200Z"
    }
   },
   "id": "521b6a4333e4b0cc"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def data_split(full_list, ratio, shuffle=False):\n",
    "    \"\"\"\n",
    "    数据集拆分: 将列表full_list按比例ratio（随机）划分为2个子列表sublist_1与sublist_2\n",
    "    :param full_list: 数据列表\n",
    "    :param ratio:     子列表1\n",
    "    :param shuffle:   子列表2\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n_total = len(full_list)\n",
    "    offset = int(n_total * ratio)\n",
    "    if n_total == 0 or offset < 1:\n",
    "        return [], full_list\n",
    "    if shuffle:\n",
    "        random.shuffle(full_list)\n",
    "    sublist_1 = full_list[:offset]\n",
    "    sublist_2 = full_list[offset:]\n",
    "    return sublist_1, sublist_2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T08:54:39.317704400Z",
     "start_time": "2024-01-19T08:54:39.303742400Z"
    }
   },
   "id": "e396eb5697ff800f"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "ds = []\n",
    "with open('bert_posneg.txt', 'r', encoding='utf-8') as reader:\n",
    "    for row in reader:\n",
    "        ds.append(row)\n",
    "ds_train, ds_test = data_split(ds, ratio=0.8, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T08:54:40.596297900Z",
     "start_time": "2024-01-19T08:54:40.424755400Z"
    }
   },
   "id": "10da96f30902f5a4"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我在上大学二年级的时候，英语阅读中有一篇课文就是节选自本书的英文原版。当时读了以后，非常认同作者的观点，并且从那是开始就暗下决心：等我有了孩子，一定要坚持给TA朗读！现在我马上要当妈妈了，所以就买了这本书，希望在宝宝出生之前好好学习一下朗读方面的知识，为今后做好准备。^_^希望更多的爸爸妈妈也能加入给孩子朗读的队伍，一起给宝宝朗读吧！\\t1\\n', '机子好用，反应快，像素略差，可以接受。\\t1\\n', '回复@日本评论:辛苦了 #1024 T少&?D# 柔情背后的非暴力不合作[晕]\\t0\\n', '最大支持容量 8GB  对以后的升级提供很大空间！\\t1\\n', '[哈哈][哈哈][哈哈]哇！?????作宣??理！[?你]\\t1\\n', '不好播卡那里太松了！\\t0\\n', '天儿的下午茶时间吗？[爱你][爱你]还有美女相陪啊！\\t1\\n', '看来现在经济形势很严峻啊，两个月前办的会员卡，才去过三次，你妹的就空屋转让了啊，我卡里的钱呢钱呢钱呢钱呢[怒][怒][怒][可怜]，@昨夜人生 随便找个剪剪吧再也不要办卡了\\t0\\n', '呵呵 假货东，华为也跟着混卖 而且还说什么未拆封之类的话 呵呵拆了有问题 就不管了 呵呵呵\\t0\\n', '【于小彤阚清子主演中国版《#继承者们#》】翻拍疑似更名《#亿万继承人#》，中韩合制共40集，主演千呼万唤始出来，已确认→#于小彤#(金叹)、#阚清子#(车恩尚)，待定中→#崔始源#(崔英道)、蒋梦婕(李宝娜)、#金喜善#，#JPM王子#、#张亮#客串←_←#翻拍是一种绝症#[失望]详细戳图↓→http:\"刚进报社那年报社刚停止无息贷款买车[泪] 听说之前貌似还有无息贷款买房哈哈...再等你半年 姐从来都是载人的人啊@星子同学 \"( ?o′) 真心被这个黑女给气疯了！太过分啦！RDV之前给我发个message说会晚个半小时，这就算了，等我到学校了，人家又发个短信来说tres malade回复 @Mr_仇:[鼓掌][鼓掌]VV，球总休了你啦！ 捧书的场景快成一道消逝的风景了。我挺喜欢＂想去＂。回味的slogan，简洁的界面，顺畅的交互，精选的内容[爱你]只是有一点我不喜欢，默认的＂专题＂，点进后却是不伦不类的杂志感[衰]第一次时我迟疑了一会不知道这和商品有何关系，就多翻几页直到出现查看更多才找到我想看的商品。现在看专题我都是快速到最后页点更多，这点很是麻烦阿！\\t0\\n']\n",
      "['不过升级了2G内存+重装了vista之后感觉还是不错的\\t1\\n', '和人家约好见面的时间，被衣服拌住喽，不得脱身，还好，我终于到了。[鼓掌]\\t1\\n', '没要什么服务，这方面不清楚\\t0\\n', '其它都好，就是??????????????颜色稍暗[嘻嘻]\\t1\\n', '现在用着挺流畅，不知道以后怎么样，拍照效果也还可以！\\t1\\n', '――“我也去打网球吧！！”   ――“你去打地鼠可以。”[衰]\\t0\\n', '京东我信任！便宜实惠邮寄快！\\t1\\n', '\"[泪][泪]#吴天明#(1939―2014)，不仅是自学成材的优秀的导演，也是一位慧眼识千里马的伯乐，在他任西影厂厂长期间，大胆启用了#张艺谋#、周晓文、黄建新、#顾长卫#等一批有艺术造诣的\"\"新人\"\"，并把他们推上了事业辉煌的顶点，使他们成为国家级/国际级的人物.....[蜡烛][蜡烛]\"\\t0\\n', '上周答应妈妈这周末回家做蛋糕[泪]失信了\\t0\\n', '午饭…三伏天木有胃口…炝炒女人菜杆儿、肉末?豌豆儿…还是木有胃口[泪][泪][泪] 青梅盐水煮白面还是好吃？@claireyang @刘杨刘杨刘大杨  我在:http:别人都以为他去了天国，唯独我知道他还在人间！[泪]\\t0\\n']\n",
      "68743\n",
      "17185\n"
     ]
    }
   ],
   "source": [
    "print(ds_test[:10])\n",
    "print(ds_train[:10])\n",
    "print(len(ds_test))\n",
    "print(len(ds_train))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T08:54:42.965321500Z",
     "start_time": "2024-01-19T08:54:42.943374600Z"
    }
   },
   "id": "7273febfc9cddec6"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "ds_train_encoded = encode_examples(ds_train).shuffle(10000).batch(batch_size)\n",
    "# test dataset\n",
    "ds_test_encoded = encode_examples(ds_test).batch(batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T09:29:26.053492200Z",
     "start_time": "2024-01-19T09:27:37.197712Z"
    }
   },
   "id": "423d278d65d99a07"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tf_model.h5:   0%|          | 0.00/478M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "341cbfb11da442feb3ecce3d9a08941c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\qcru\\IQue\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hWX1082773\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "# recommended learning rate for Adam 5e-5, 3e-5, 2e-5\n",
    "learning_rate = 2e-5\n",
    "# we will do just 1 epoch, though multiple epochs might be better as long as we will not overfit the model\n",
    "number_of_epochs = 1\n",
    "# model initialization\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-chinese')\n",
    "# choosing Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
    "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T09:02:52.013057700Z",
     "start_time": "2024-01-19T09:02:00.762336100Z"
    }
   },
   "id": "93010485d3d009c2"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2865/2865 [==============================] - ETA: 0s - loss: 0.1859 - accuracy: 0.9294"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds_train_encoded\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumber_of_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mds_test_encoded\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbert_sentiment\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1832\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1816\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[0;32m   1818\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[0;32m   1819\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1830\u001B[0m         pss_evaluation_shards\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pss_evaluation_shards,\n\u001B[0;32m   1831\u001B[0m     )\n\u001B[1;32m-> 1832\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1833\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1834\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1835\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1836\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1837\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1838\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1839\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1840\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1841\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1842\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1843\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1844\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1845\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1846\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   1847\u001B[0m }\n\u001B[0;32m   1848\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:2272\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   2268\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   2269\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   2270\u001B[0m             ):\n\u001B[0;32m   2271\u001B[0m                 callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[1;32m-> 2272\u001B[0m                 logs \u001B[38;5;241m=\u001B[39m \u001B[43mtest_function_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2273\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2274\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdata_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2275\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2276\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pss_evaluation_shards\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2277\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2279\u001B[0m logs \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39msync_to_numpy_or_python_type(logs)\n\u001B[0;32m   2280\u001B[0m \u001B[38;5;66;03m# Override with model metrics instead of last step logs\u001B[39;00m\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:4079\u001B[0m, in \u001B[0;36m_TestFunction.run_step\u001B[1;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001B[0m\n\u001B[0;32m   4078\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001B[1;32m-> 4079\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4080\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   4081\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:876\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    873\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    874\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    875\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 876\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[0;32m    880\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    881\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1266\u001B[0m     args,\n\u001B[0;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1268\u001B[0m     executing_eagerly)\n\u001B[0;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    262\u001B[0m     )\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1494\u001B[0m   )\n",
      "File \u001B[1;32mD:\\qcru\\IQue\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[0;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[0;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[0;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[0;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[0;32m     59\u001B[0m   ]\n\u001B[1;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(ds_train_encoded, epochs=number_of_epochs, validation_data=ds_test_encoded)\n",
    "model.save('bert_sentiment')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T13:47:48.653377200Z",
     "start_time": "2024-01-19T09:32:09.870336600Z"
    }
   },
   "id": "beba377742430021"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_sentence = \"房间OK，但隔音差，服务也不错，地理位置不太理想。\"\n",
    "\n",
    "predict_input = tokenizer.encode(test_sentence,\n",
    "truncation=True,\n",
    "padding=True,\n",
    "return_tensors=\"tf\")\n",
    "\n",
    "tf_output = model.predict(predict_input)[0]\n",
    "tf_prediction = tf.nn.softmax(tf_output, axis=1)\n",
    "print(tf_prediction)\n",
    "labels = ['Negative','Positive'] #(0:negative, 1:positive)\n",
    "label = tf.argmax(tf_prediction, axis=1)\n",
    "label = label.numpy()\n",
    "print(labels[label[0]])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54c6556d1531c643"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
